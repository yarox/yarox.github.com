<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>The Underlying Beauty</title><link href="http://yarox.github.com/" rel="alternate"></link><link href="http://yarox.github.com/feeds/all.atom.xml" rel="self"></link><id>http://yarox.github.com/</id><updated>2013-03-21T00:00:00+01:00</updated><entry><title>WallÂ Follower</title><link href="http://yarox.github.com/2013/03/wall-follower.html" rel="alternate"></link><updated>2013-03-21T00:00:00+01:00</updated><author><name>Adrian Martin</name></author><id>tag:yarox.github.com,2013-03-21:2013/03/wall-follower.html</id><summary type="html">&lt;p&gt;The objective of this experiment is to build a robot capable of following walls, but instead of creating fixed rules telling the robot what to do, we will use a more flexible evolutionary&amp;nbsp;approach.&lt;/p&gt;
&lt;div class="section" id="introduction"&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;To follow a wall, or in a more general sense, to follow the contours of an object, is an important behavior for autonomous mobile robots. Robots operating in an unknown, unstructured environment use their sensors to perceive the surroundings and plan their motions or trajectories&amp;nbsp;accordingly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="approach"&gt;
&lt;h2&gt;Approach&lt;/h2&gt;
&lt;p&gt;Control systems for autonomous robots are often programmed directly by researchers or designers. Such control programs can be very complex. Researchers must anticipate which abilities a given robot will need, and then formulate these into a control program or control&amp;nbsp;hierarchy.&lt;/p&gt;
&lt;p&gt;As the complexity of an environment and task for a given autonomous robot increases, the difficulty of designing an adequate control system by hand becomes a limiting factor in the degree of functional complexity that can be achieved. A potential solution to this problem is to develop methods that allow robots to learn how to perform complex tasks&amp;nbsp;automatically.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Evolutionary computation&lt;/em&gt; is a subfield of artificial intelligence that involves combinatorial optimization problems. This approach uses iterative progress, such as growth or development in a population. This population is then selected in a guided random search to achieve the desired&amp;nbsp;end.&lt;/p&gt;
&lt;p&gt;In our case, we use an &lt;em&gt;artificial neural networks&lt;/em&gt; as a control system and an evolutionary algorithm as a training method. This combination is commonly known as &lt;em&gt;neuroevolution&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;We chose the &lt;em&gt;differential evolution&lt;/em&gt; (&lt;span class="caps"&gt;DE&lt;/span&gt;) method as the evolutionary algorithm to train our neural networks. This method optimizes a problem by maintaining a population of candidate solutions and creating new candidate solutions by combining existing ones according to a simple formulae, and then keeping whichever candidate solution has the best fitness on the optimization problem at hand. Basically, &lt;span class="caps"&gt;DE&lt;/span&gt; adds the weighted difference between two population vectors to a third vector. This way no separate probability distribution has to be used which makes the scheme completely&amp;nbsp;self-organizing.&lt;/p&gt;
&lt;p&gt;Successful evolution of intelligent autonomous robot controllers is ultimately dependent on the formulation of suitable &lt;em&gt;fitness functions&lt;/em&gt; that are capable of selecting for successful behaviors without specifying the low-level implementation details of those&amp;nbsp;behaviors.&lt;/p&gt;
&lt;p&gt;We can distinguish between various kinds of fitness functions based on the degree of a priori knowledge introduced by designer (in descending&amp;nbsp;order):&lt;/p&gt;
&lt;blockquote&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;&lt;strong&gt;Training&amp;nbsp;data&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Fitness is maximized when the system in question produces a minimum output error when presented with a given set of inputs with a known set of optimal associated&amp;nbsp;outputs.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Behavioral&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Task-specific hand-formulated functions that measure various aspects of what a robot is doing and how it is doing it. These types of functions generally include several sub-functions or terms that are combined into a weighted sum or product. These sub-functions or terms are intended to measure simple action-response behaviors, low-level sensor-actuator mappings, or other events/features local to the&amp;nbsp;robot.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Functional&amp;nbsp;incremental&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;The evolutionary process begins by selecting for a simple ability upon which a more complex overall behavior can be built. Once the simple ability is evolved, the fitness function is altered or augmented to select for a more complex behavior. This sequence of evolution followed by fitness function augmentation continues until eventually the desired final behavior is achieved. The overall process can be considered one of explicit training for simple sub-behaviors followed by training for successively more complex&amp;nbsp;behaviors.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Tailored&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Contain aggregate terms that measure some degree or aspect of task completion that is divorced from any particular behavior or method. Hence, tailored fitness functions combine elements from behavioral fitness functions and aggregate fitness&amp;nbsp;functions.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Environmental&amp;nbsp;incremental&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Rather than simply increasing the complexity of the fitness selection function, one form of incremental evolution involves augmenting the difficulty of the environment in which the robots must&amp;nbsp;operate.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Competitive and&amp;nbsp;co-competitive&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Utilize direct competition between members of an evolving population. in competitive evolution robot controllers compete against one another within the same environment so that the behavior of one robot directly influences the behavior, and therefore fitness evaluation, of another. In co-competitive evolution two separate populations (performing distinct tasks) compete against each other within the same&amp;nbsp;environment.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Aggregate&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Select only for high-level success or failure to complete a task without regard to how the task was completed. This type of selection reduces injection of human bias into the evolving system by aggregating the evaluation of benefit (or deficit) of all of the robot&amp;#8217;s behaviors into a single success/failure&amp;nbsp;term.&lt;/dd&gt;
&lt;/dl&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="section" id="implementation"&gt;
&lt;h2&gt;Implementation&lt;/h2&gt;
&lt;p&gt;The robot has two laser sensors and a motion actuator. The laser sensors returns the distance to the closest object, and the motion actuator recieves the values of linear and angular speed and applies them to the robot as direct&amp;nbsp;translation.&lt;/p&gt;
&lt;img alt="robot overview" src="https://dl.dropbox.com/u/18317072/robot.png" /&gt;
&lt;p&gt;A &lt;em&gt;feed forward neural network&lt;/em&gt; (&lt;span class="caps"&gt;FFANN&lt;/span&gt;) with two inputs and two outputs is used to control our robot. For the activation function, we used a &lt;em&gt;logistic function&lt;/em&gt; bounded between &lt;cite&gt;-5&lt;/cite&gt; and &lt;cite&gt;5&lt;/cite&gt;. We feed the &lt;span class="caps"&gt;FFANN&lt;/span&gt; with the values from the two laser sensors, and send the output to the motion actuator. This causes the robot to move around the&amp;nbsp;environment.&lt;/p&gt;
&lt;img alt="controller overview" src="https://dl.dropbox.com/u/18317072/controller.png" /&gt;
&lt;p&gt;The weights of the FFANNs are evolved using the differential evolution algorithm with the following parameters: weighting factor &lt;cite&gt;F = 0.8&lt;/cite&gt;, crossover constant &lt;cite&gt;&lt;span class="caps"&gt;CR&lt;/span&gt; = 0.9&lt;/cite&gt;, and number of parents &lt;cite&gt;&lt;span class="caps"&gt;NP&lt;/span&gt; = 20&lt;/cite&gt;.&lt;/p&gt;
&lt;p&gt;We let the system evolve for &lt;cite&gt;20&lt;/cite&gt; generations. In each generation, the fitness of a robot is calculated as the average fitness obtained after two executions, each execution lasting &lt;cite&gt;100&lt;/cite&gt; clock&amp;nbsp;cycles.&lt;/p&gt;
&lt;p&gt;An aggregate fitness function was designed with an energetic model in mind: a robot could gain or lose energy depending on her actions when moving around the environment. Thus, the fitness is determined only by the energy level at the end of the evaluation&amp;nbsp;period.&lt;/p&gt;
&lt;p&gt;To implement this model, several objects (&amp;#8220;cookies&amp;#8221;) were placed near the walls. The more &amp;#8220;cookies&amp;#8221; a robot gets during its execution time, the higher its energy. We assume that a robot that has managed to get a large number of &amp;#8220;cookies&amp;#8221; (and therefore energy) has developed a controller that allows her to follow the walls&amp;nbsp;efficiently.&lt;/p&gt;
&lt;p&gt;The whole process can be summarized as&amp;nbsp;follows:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;Create a&amp;nbsp;robot.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Create a population of networks. For each&amp;nbsp;generation:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;Perturbate the current population creating a candidate population. For each candidate&amp;nbsp;network:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Set the network as the robot&amp;nbsp;controller.&lt;/li&gt;
&lt;li&gt;Put the robot in the middle of the room and start the&amp;nbsp;evaluation.&lt;/li&gt;
&lt;li&gt;The network fitness is the final robot&amp;nbsp;energy.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Once we have evaluated the whole candidate population, the selection process starts, yielding a new current&amp;nbsp;population.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Return the network with the highest&amp;nbsp;fitness.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="results"&gt;
&lt;h2&gt;Results&lt;/h2&gt;
&lt;p&gt;At the end of the 20 generations the &lt;span class="caps"&gt;DE&lt;/span&gt; algorithm had converged significantly. The following figure shows how the fitness of the population improved, reaching maximum levels. Although there is some room for improvement, we will accept this suboptimal result due to long simulation&amp;nbsp;times.&lt;/p&gt;
&lt;img alt="fitness evolution" src="https://dl.dropbox.com/u/18317072/fitness_evo.png" style="width: 700px;" /&gt;
&lt;p&gt;&lt;a class="reference external" href="http://youtu.be/ffNPedVsot4"&gt;Next&lt;/a&gt; video shows the best robot in action. As evidence shows, we can conclude that her has managed to develop the task satisfactorily, even though maximum fitness level was not&amp;nbsp;reached.&lt;/p&gt;
&lt;p&gt;In this &lt;a class="reference external" href="http://youtu.be/unuObGm6SQ0"&gt;other&lt;/a&gt; video, we can see an evolution overview, showing the behavior of the best robot of each generation. At first, robots move randomly, but after a short period of time, they learn to stay at a distance of the walls. Finally, they manage to get most of the &amp;#8220;cookies&amp;#8221; during their evaluation time. The fact that they seems to prefer turning to the right is due to&amp;nbsp;chance.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Automatic robot controller development methods that do not require hand coding or in-depth human knowledge are potentially of great value because it may be possible to apply them to domains in which humans have insufficient knowledge to develop adequate controllers&amp;nbsp;directly.&lt;/p&gt;
&lt;p&gt;Under a short number of iterations and with a small population, a near optimum behavior was achieved. We introduced very little knowledge about the problem into the robots; they exploited the environment and their bodies, improving their fitness generation after&amp;nbsp;generation.&lt;/p&gt;
&lt;p&gt;We have shown that this approach is simple, yet flexible and powerful. It can be applied to more complex domains, taking into account that the difficult part is coming up with a good fitness&amp;nbsp;function.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="references"&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Artificial neural network. (2012, October 13). In Wikipedia, The Free Encyclopedia. Retrieved 07:46, October 18, 2012, from &lt;a class="reference external" href="http://en.wikipedia.org/w/index.php?title=Artificial_neural_network&amp;amp;oldid=517534177"&gt;http://en.wikipedia.org/w/index.php?title=Artificial_neural_network&amp;amp;oldid=517534177&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Feedforward neural network. (2012, September 21). In Wikipedia, The Free Encyclopedia. Retrieved 07:32, October 18, 2012, from &lt;a class="reference external" href="http://en.wikipedia.org/w/index.php?title=Feedforward_neural_network&amp;amp;oldid=513807431"&gt;http://en.wikipedia.org/w/index.php?title=Feedforward_neural_network&amp;amp;oldid=513807431&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Evolutionary computation. (2012, October 1). In Wikipedia, The Free Encyclopedia. Retrieved 07:34, October 18, 2012, from &lt;a class="reference external" href="http://en.wikipedia.org/w/index.php?title=Evolutionary_computation&amp;amp;oldid=515418753"&gt;http://en.wikipedia.org/w/index.php?title=Evolutionary_computation&amp;amp;oldid=515418753&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Storn, R., &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; Price, K. (1997). Differential Evolution â A Simple and Efficient Heuristic for Global Optimization over Continuous Spaces. Journal of Global Optimization, 11(4), 341-359. Springer. Retrieved from &lt;a class="reference external" href="http://www.springerlink.com/index/X555692233083677.pdf"&gt;http://www.springerlink.com/index/X555692233083677.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Nelson, A. L., Barlow, G. J., &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; Doitsidis, L. (2009). Fitness functions in evolutionary robotics: A survey and analysis. Robotics and Autonomous Systems, 57(4), 345-370. Elsevier &lt;span class="caps"&gt;B.V.&lt;/span&gt; Retrieved from &lt;a class="reference external" href="http://www.nelsonrobotics.org/paper_archive_nelson/nelson-jras-2009.pdf"&gt;http://www.nelsonrobotics.org/paper_archive_nelson/nelson-jras-2009.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Braitenberg, V. (1986). Vehicles: Experiments in Synthetic Psychology.&amp;nbsp;&lt;span class="caps"&gt;MIT&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Binti, R. (2005). Wall Following Mobile Robot. Kolej Universiti Teknikal Kebangsaan Malaysia. Retrieved from &lt;a class="reference external" href="http://library.utem.edu.my/index2.php?option=com_docman&amp;amp;task=doc_view&amp;amp;gid=3878&amp;amp;Itemid=208"&gt;http://library.utem.edu.my/index2.php?option=com_docman&amp;amp;task=doc_view&amp;amp;gid=3878&amp;amp;Itemid=208&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</summary><category term="python"></category><category term="robots"></category><category term="simulation"></category><category term="evolution"></category><category term="neural networks"></category></entry><entry><title>Commuting Patterns in the IvoryÂ Coast</title><link href="http://yarox.github.com/2013/03/commuting-patterns-in-the-ivory-coast.html" rel="alternate"></link><updated>2013-03-08T00:00:00+01:00</updated><author><name>Adrian Martin</name></author><id>tag:yarox.github.com,2013-03-08:2013/03/commuting-patterns-in-the-ivory-coast.html</id><summary type="html">&lt;p&gt;Orange &lt;a class="reference external" href="http://www.d4d.orange.com/home"&gt;Data for Development&lt;/a&gt; is an open data challenge encouraging research teams around the world to use four datasets of anonymous call patterns of Orange&amp;#8217;s Ivory Coast subsidiary, to help address society development questions in novel ways. The data sets are based on anonymized call detail records extracted from Orange&amp;#8217;s customer base, covering the months of December 2011 to April&amp;nbsp;2012.&lt;/p&gt;
&lt;a class="reference external image-reference" href="http://github.com/yarox/d4d-visor"&gt;&lt;img alt="d4d visor" src="https://raw.github.com/yarox/d4d-visor/master/thumbnail.png" style="width: 800px;" /&gt;&lt;/a&gt;
&lt;p&gt;Our &lt;a class="reference external" href="http://labs.paradigmatecnologico.com/2012/11/15/d4d-challenge-accepted/"&gt;team&lt;/a&gt; used the geolocation data from call detail records extracted from Orange&amp;#8217;s customer base in order to know in which areas the customers have been moving around, to help us discover the morning and evening rush hours: the time when users were commuting between their place of residence and place of&amp;nbsp;work.&lt;/p&gt;
&lt;div class="section" id="visualization"&gt;
&lt;h2&gt;Visualization&lt;/h2&gt;
&lt;p&gt;We used &lt;a class="reference external" href="http://www.python.org/"&gt;Python&lt;/a&gt; for crunching the numbers and &lt;a class="reference external" href="http://d3js.org/"&gt;D3.js&lt;/a&gt; for creating the&amp;nbsp;visualization.&lt;/p&gt;
&lt;div class="section" id="bar-chart"&gt;
&lt;h3&gt;Bar&amp;nbsp;Chart&lt;/h3&gt;
&lt;p&gt;The bar chart shows the total population density at a fixed time slot. Rush ours can be identified by the two peaks that emerge every day, one in the morning and one in the&amp;nbsp;afternoon.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="choropleth"&gt;
&lt;h3&gt;Choropleth&lt;/h3&gt;
&lt;p&gt;The choropleth shows how the population density flows over time, as people move from one region to another. Notice how the density increases (areas get darker) as the time gets closer to the rush&amp;nbsp;hours.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="take-a-look"&gt;
&lt;h2&gt;Take a&amp;nbsp;look!&lt;/h2&gt;
&lt;p&gt;If you want to see it running, clone the &lt;a class="reference external" href="http://github.com/yarox/d4d-visor"&gt;repo&lt;/a&gt; and start a local web server. For example, you can run Python&amp;#8217;s built-in&amp;nbsp;server:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;python -m SimpleHTTPServer 8888 &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;or Node.js&amp;#8217; &lt;a class="reference external" href="http://github.com/nodeapps/http-server"&gt;http-server&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;http-server -p 8888 &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once this is running, go to &lt;a class="reference external" href="http://localhost:8888/"&gt;http://localhost:8888/&lt;/a&gt; and use the &lt;strong&gt;up&lt;/strong&gt; and &lt;strong&gt;down&lt;/strong&gt; keys to change between days, and the &lt;strong&gt;left&lt;/strong&gt; and &lt;strong&gt;right&lt;/strong&gt; keys to move between&amp;nbsp;hours.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="visualization"></category><category term="python"></category><category term="d3"></category></entry><entry><title>Hello,Â World!</title><link href="http://yarox.github.com/2013/01/hello-world.html" rel="alternate"></link><updated>2013-01-01T00:00:00+01:00</updated><author><name>Adrian Martin</name></author><id>tag:yarox.github.com,2013-01-01:2013/01/hello-world.html</id><summary type="html">&lt;p&gt;Now we&amp;#8217;re&amp;nbsp;talking.&lt;/p&gt;
</summary><category term="self"></category></entry></feed>